
<h1 align="center">
  <p>WorldRWKV: Exploring RWKV7â€™s Understanding Capabilities of Any Modality in the World</p>
</h1>

\[ English | [ä¸­æ–‡](README_zh.md) \]
# ç®€ä»‹
æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç”¨çº¯RWKV7æ¶æ„å®ç°ä»»æ„æ¨¡æ€è®­ç»ƒæ¨ç†ï¼›ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨encoderæ¥ä»»æ„åˆ‡æ¢æ¨¡æ€çš„è¾“å…¥å¹¶è¾“å‡ºæ–‡æœ¬ã€‚æœªæ¥é€æ­¥å®ç°ç«¯åˆ°ç«¯çš„è·¨æ¨¡æ€æ¨ç†ï¼Œå¹¶ä¸”ä½¿ç”¨RWKV7æ¥æ¢ç´¢World Modelçš„é›å½¢ã€‚ç›®å‰é¡¹ç›®å¤„äºåˆæœŸé˜¶æ®µï¼Œä»ç„¶æœ‰å¾ˆå¤šåœ°æ–¹éœ€è¦ä¼˜åŒ–ï¼Œæ¬¢è¿åŠ å…¥æˆ‘ä»¬ã€‚
- æ¨¡å‹ä¸‹è½½ï¼š[HFModel](https://huggingface.co/WorldRWKV).  
- æ¼”ç¤ºåœ°å€ï¼š[Demo](https://shoumenchougou.github.io/testforvideo/)
- åŠ å…¥æˆ‘ä»¬ï¼š[Discord](https://discord.com/invite/bDSBUMeFpc) QQ: 1015471226

## å‘å¸ƒ
- [3/7] ğŸ”¥ å‘å¸ƒä»“åº“ **WorldRWKV: Exploring RWKV7â€™s Understanding Capabilities of Any Modality in the World**. è®­ç»ƒç»†èŠ‚ä»¥åŠç›¸å…³è®ºæ–‡å°†åœ¨ä¸‹å‘¨å‘å¸ƒ [HFModel](https://huggingface.co/WorldRWKV).

# ç¯å¢ƒ
- å…‹éš†ä»“åº“å¹¶è¿›å…¥æ–‡ä»¶
```
git clone https://github.com/JL-er/WorldRWKV.git
cd WorldRWKV
```
- ä¾èµ–
```
conda create -n world python=3.12
conda activate world
pip install -r requirements.txt #ä¸­å›½ç”¨æˆ·æ·»åŠ -i https://pypi.tuna.tsinghua.edu.cn/simple
# æ¨è torch=>2.4.0
```

# æ¨ç†
> [!NOTE]
> è¯·ç¡®ä¿encoder modelå’Œencoder_typeåŒ¹é…. æ›´å¤šç»†èŠ‚åœ¨:world/world_encoder.py
```
from infer.worldmodel import Worldinfer
from PIL import Image


llm_path='/home/rwkv/model/rwkv7-3b-siglip/rwkv-0'
encoder_path='/home/rwkv/model/siglip2basep16s384'
encoder_type='siglip' #[clip, whisper, siglip, speech]

model = Worldinfer(model_path=llm_path, encoder_type=encoder_type, encoder_path=encoder_path)

img_path = './docs/03-Confusing-Pictures.jpg'
image = Image.open(img_path).convert('RGB')

text = '\x16User: What is unusual about this image?\x17Assistant:'

result = model.generate(text, image)

print(result)
```
## Web-demo (Using Gradio)
```
python audio_multiturns_web.py # For Audio QA and ASR
 
python visual_web.py  # For Visual QA 

```

# è®­ç»ƒ
> [!NOTE]
> è¯·ç¡®ä¿encoder modelå’Œencoder_typeåŒ¹é…ï¼Œä»¥åŠè®­ç»ƒä»»åŠ¡ä¸data_typeåŒ¹é…ã€‚ä½ ä¹Ÿå¯ä»¥åœ¨world/world_encoder.pyä¸­æ³¨å†Œè‡ªå·±çš„encoderç±»
```
load_model=/home/rwkvos/model/rwkv/RWKV-x070-World-2.9B-v3-20250211-ctx4096.pth
proj_dir=/home/rwkvos/peter/out_model/rwkv7-3b-pretrain-siglip
data_file=/home/rwkvos/data/hf-imgs/pretrain595

n_layer=32
n_embd=2560

encoder_path="google/siglip2-base-patch16-384" #é€‰æ‹©ä½ éœ€è¦çš„encoder
encoder_type=siglip #åœ¨worldencoderä¸­æ³¨å†Œç±»å‹
data_type=hf_img #æ•°æ®ç±»å‹

micro_bsz=32
epoch_save=1
epoch_steps=18605 
ctx_len=2048


HF_ENDPOINT="https://hf-mirror.com" python world_train.py \   # ä¸­å›½ç”¨æˆ·ä½¿ç”¨"https://hf-mirror.com"ä¸‹è½½æ¨¡å‹
--load_model $load_model \
--proj_dir $proj_dir --data_file $data_file \
--data_type $data_type \
--vocab_size 65536 \
--n_layer $n_layer --n_embd $n_embd \
--ctx_len $ctx_len --micro_bsz $micro_bsz \
--epoch_steps $epoch_steps --epoch_count 1 --epoch_begin 0 --epoch_save $epoch_save \
--lr_init 1e-3 --lr_final 0 --warmup_steps 0 --beta1 0.9 --beta2 0.99 --adam_eps 1e-8 \
--accelerator gpu --devices 8 --precision bf16 --strategy deepspeed_stage_1 --grad_cp 1 \
--encoder_path $encoder_path --encoder_type $encoder_type \
--my_testing "x070" --train_step adapter rwkv #train_step é€‰æ‹©ä½ è¦è®­ç»ƒçš„éƒ¨åˆ†ï¼Œencoderã€adapterã€rwkv
```

# åŠŸèƒ½
### WorldRWKVå·²å®ç°çš„åŠŸèƒ½ä»¥åŠåç»­æ·»åŠ çš„åŠŸèƒ½
| Function      | Work |
|:--------------:|:-----------:|
| asr            | âœ…          |
| speech to text | âœ…          |
| visual to text | âœ…          |
| text to speech | âŒ          |
| text to visual | âŒ          |
|speech to speech| âŒ          |


# è§†è§‰æŒ‡æ ‡

| **Encoder** | **LLM** | **VQAV2** | **TextVQA** | **GQA** | **ScienceQA** |
|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|:--------------:|
| [**Clip**](https://huggingface.co/openai/clip-vit-large-patch14-336)    | RWKV7-0.4B     | 62.04      | 31.72      | 49.32       |   51.10         |
|| RWKV7-1.5B     | 72.31       | 40.27       | 54.56       |   62.77          |
|             | RWKV7-3B       | 73.13       | 45.56       | 57.00       | 70.06       |
| [**SigLIP2**](https://huggingface.co/google/siglip2-base-patch16-384) | RWKV7-0.4B     |    72.04     | 38.75       | 55.52       | 43.32       |
|             | RWKV7-1.5B     |     76.95    | 44.96       | 58.88       | 63.10       |
|             | RWKV7-3B       |     78.30     |   51.09          |   60.75          |     70.93        |

# è¯­éŸ³æŒ‡æ ‡

| **Encoder** | **LLM** | **LibriSpeech** | **Aishell-1** |
|:--------------:|:--------------:|:--------------:|:--------------:|
|[**wavlm large**](https://huggingface.co/microsoft/wavlm-large) | RWKV7-0.4B | 2.51%(clean) | 9.68%(dev) |
|            |            | 7.72%(other) | 10.21%(test) |

## è¯­éŸ³è¯†åˆ« & è¯­éŸ³é—®ç­” (Demo)
| **Encoder** | **LLM** | **task** | **Checkpoint** |
|:--------------:|:--------------:|:--------------:|:--------------:|
|[**wavlm large**](https://huggingface.co/microsoft/wavlm-large) | RWKV7-0.1B | EN asr|[WorldRWKV/RWKV7-0.1B-wavlmLarge-ENASR-demo](https://huggingface.co/WorldRWKV/RWKV7-0.1B-wavlmLarge-ENASR-demo)|
|            |     RWKV7-0.4B       | EN asr|[WorldRWKV/RWKV7-0.4B-wavlmLarge-ENASR-demo](https://huggingface.co/WorldRWKV/RWKV7-0.4B-wavlmLarge-ENASR-demo)|
|            |     RWKV7-0.4B       | CN asr|[WorldRWKV/RWKV7-0.4B-wavlmLarge-CNASR-demo](https://huggingface.co/WorldRWKV/RWKV7-0.4B-wavlmLarge-CNASR-demo)|
|            |     RWKV7-0.4B       | EN qa|[WorldRWKV/RWKV7-0.4B-wavlmLarge-ENQA-demo](https://huggingface.co/WorldRWKV/RWKV7-0.4B-wavlmLarge-ENQA-demo)|
