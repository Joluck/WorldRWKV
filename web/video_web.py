import gradio as gr
from infer.worldmodel import Worldinfer
from PIL import Image
import re
import torch
import random
from PIL import Image
from decord import VideoReader
from decord import cpu
import os

# åˆå§‹åŒ–æ¨¡å‹
llm_path = '/home/rwkv/alic-li/WorldRWKV/rwkv7-0.4b-video-siglip-ocr-base/rwkv-0'
encoder_path = 'google/siglip2-base-patch16-384'
encoder_type = 'siglip'

enable_think = False
# å…¨å±€å˜é‡å­˜å‚¨å½“å‰ä¸Šä¼ çš„è§†é¢‘å…³é”®å¸§å’Œæ¨¡å‹çŠ¶æ€
current_video_frames = None  # å­˜å‚¨å…³é”®å¸§åˆ—è¡¨
current_state = None 
first_question = False 
# æ˜¯å¦æ˜¯ç¬¬ä¸€è½®å¯¹è¯
# åˆå§‹åŒ–æ¨¡å‹
model = Worldinfer(model_path=llm_path, encoder_type=encoder_type, encoder_path=encoder_path)

# å¤„ç†ç”¨æˆ·è¾“å…¥çš„æ ¸å¿ƒé€»è¾‘
import html  # å¯¼å…¥htmlåº“


def frame_att_generator(video_path, threshold=0.05, min_k=3, max_k=10):
    vr = VideoReader(video_path, ctx=cpu(0))  # ä½¿ç”¨ CPU è§£ç 
    fps = vr.get_avg_fps()  # è·å–è§†é¢‘å¹³å‡å¸§ç‡
    sampling_interval = int(fps)  # æ¯ç§’é‡‡æ ·ä¸€å¸§ä½œä¸ºåŸºå‡†

    frames = []
    frames_flattened = []

    for idx in range(len(vr)):
        # åªå¯¹é‡‡æ ·å¸§è¿›è¡Œå¤„ç†
        if idx % sampling_interval == 0:
            frame = vr[idx].asnumpy()  # è½¬æ¢ä¸º numpy æ•°ç»„
            frame_rgb = frame / 255.0  # å½’ä¸€åŒ–åˆ° [0, 1]
            frame_tensor = torch.tensor(frame_rgb).permute(2, 0, 1).half()
            flat = frame_tensor.reshape(-1)  # å±•å¹³ç¼“å­˜
            frames.append(frame_tensor)
            frames_flattened.append(flat)

    if len(frames) <= 1:
        return frames

    # æ‰¹é‡è®¡ç®—å¸§å·®
    flattened_tensor = torch.stack(frames_flattened)  # shape: (N, C*H*W)
    diffs = torch.mean(torch.abs(flattened_tensor[1:] - flattened_tensor[:-1]), dim=1)
    selected_indices_sampled = [0] + [i + 1 for i, diff in enumerate(diffs) if diff > threshold]

    K = len(selected_indices_sampled)

    # å¦‚æœå¸§å¤ªå°‘ï¼Œè¡¥å……éšæœºå¸§
    if K < min_k:
        candidates = [i for i in range(len(frames)) if i not in selected_indices_sampled]
        missing = min_k - K
        selected_indices_sampled += random.sample(candidates, missing)
        selected_indices_sampled = sorted(selected_indices_sampled)

    # å¦‚æœå¸§å¤ªå¤šï¼Œä¿ç•™å‰ max_k ä¸ªå·®å¼‚æœ€å¤§çš„å¸§
    elif K > max_k:
        frame_diffs = [(diff.item(), i + 1) for i, diff in enumerate(diffs)]
        frame_diffs.sort(reverse=True, key=lambda x: x[0])
        top_indices = [0] + [idx for diff, idx in frame_diffs[:max_k - 1]]
        selected_indices_sampled = sorted(top_indices)

    # è¿”å› PIL.Image.Image å›¾ç‰‡åˆ—è¡¨
    return [
        Image.fromarray((frames[i].permute(1, 2, 0).cpu().numpy() * 255).astype("uint8"))
        for i in selected_indices_sampled
    ]
def chat_fn(user_input, chat_history, video=None):
    global current_video_frames, current_state, first_question

    # å¦‚æœä¸Šä¼ äº†æ–°è§†é¢‘ï¼Œæ›´æ–°å½“å‰è§†é¢‘å¸§å¹¶é‡ç½®çŠ¶æ€
    if video is not None:
        current_video_frames = frame_att_generator(video)

    # å¦‚æœæ²¡æœ‰è§†é¢‘å¸§ï¼Œæç¤ºç”¨æˆ·ä¸Šä¼ 
    if current_video_frames is None or len(current_video_frames) == 0:
        bot_response = "è¯·å…ˆä¸Šä¼ ä¸€ä¸ªè§†é¢‘ï¼"
        chat_history.append((user_input, bot_response))
        return "", chat_history

    # æ„é€ æç¤ºæ–‡æœ¬
    prompt = f'\x16User: {user_input}\x17Assistant:'

    # ç”Ÿæˆç»“æœï¼Œä¼ å…¥å½“å‰çŠ¶æ€
    try:
        if first_question:
            result, state = model.generate(prompt, current_video_frames[0], state=None)  # ä½¿ç”¨ç¬¬ä¸€å¸§ä½œä¸ºåˆå§‹å›¾åƒ
        else:
            result, state = model.generate(prompt, 'none', state=current_state)

        first_question = False
        bot_response, current_state = result, state
        if enable_think == True:
            # è§£æ</think>æ ‡ç­¾
            think_pattern = re.compile(r'</think>', re.DOTALL)
            think_matches = think_pattern.findall(bot_response)

            # è§£æ<answer></answer>æ ‡ç­¾
            answer_pattern = re.compile(r'<answer>(.*?)</answer>', re.DOTALL)
            answer_matches = answer_pattern.findall(bot_response)

            # æ„é€ æœ€ç»ˆçš„è¾“å‡º
            final_response = ""
            for match in think_matches:
                final_response += f"<details><summary>Think ğŸ¤” </summary>{html.escape(match)}</details>"

            for match in answer_matches:
                final_response += "Answer ğŸ’¡"
                final_response += "\n"
                final_response += html.escape(match)

            # è½¬ä¹‰HTMLæ ‡ç­¾
            bot_response = final_response

    except Exception as e:
        bot_response = f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}"
        current_state = None  # å‡ºé”™æ—¶é‡ç½®çŠ¶æ€

    # æ›´æ–°å¯¹è¯å†å²
    chat_history.append((user_input, bot_response))

    # è¿”å›æ›´æ–°åçš„ç»„ä»¶çŠ¶æ€
    return "", chat_history  # æ¸…ç©ºè¾“å…¥æ¡†ï¼Œæ›´æ–°èŠå¤©è®°å½•# å¤„ç†å›¾ç‰‡ä¸Šä¼ 
def update_video(video_path):
    global current_video_frames, current_state, first_question
    if video_path is not None:
        current_video_frames = frame_att_generator(video_path)  # æå–å…³é”®å¸§
        current_state = None
        first_question = True
        return "è§†é¢‘å·²ä¸Šä¼ æˆåŠŸï¼å¯ä»¥å¼€å§‹æé—®äº†ã€‚"
    else:
        return "è§†é¢‘ä¸Šä¼ å¤±è´¥ï¼Œè¯·é‡æ–°ä¸Šä¼ ã€‚"

# æ¸…ç©ºå›¾ç‰‡
def clear_image():
    global current_state, current_video_frames
    current_video_frames = None  
    current_state = None 
    return None, "å›¾ç‰‡å·²æ¸…é™¤ï¼Œè¯·ä¸Šä¼ æ–°å›¾ç‰‡ã€‚"

# æ¸…ç©ºå†å²å’Œå›¾ç‰‡
def clear_all():
    global current_video_frames, current_state
    current_video_frames = None
    current_state = None
    return [], "", "å›¾ç‰‡å’Œå¯¹è¯å·²æ¸…ç©ºï¼Œè¯·é‡æ–°ä¸Šä¼ å›¾ç‰‡ã€‚"

def chat_without_video_update(user_input, chat_history):
    return chat_fn(user_input, chat_history)

# ç•Œé¢å¸ƒå±€ç»„ä»¶
with gr.Blocks(title="WORLD RWKV", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# WORLD RWKV")
    gr.Markdown("ä¸Šä¼ ä¸€ä¸ªè§†é¢‘ï¼Œç„¶åå¯ä»¥è¿›è¡Œå¤šè½®æé—®")

    with gr.Row():
        # å·¦ä¾§è§†é¢‘ä¸Šä¼ åŒº
        with gr.Column(scale=2):
            video_input = gr.Video(
                label="ä¸Šä¼ è§†é¢‘",
                height=400
            )

            # è§†é¢‘çŠ¶æ€å’Œæ“ä½œ
            with gr.Row():
                video_status = gr.Textbox(
                    label="è§†é¢‘çŠ¶æ€", 
                    value="è¯·ä¸Šä¼ è§†é¢‘", 
                    interactive=False
                )
                clear_video_btn = gr.Button("åˆ é™¤è§†é¢‘")

        # å³ä¾§å¯¹è¯åŒº
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                label="å¯¹è¯è®°å½•",
                bubble_full_width=False,
                height=500
            )

    # æ§åˆ¶åŒºåŸŸ
    with gr.Row():
        # è¾“å…¥ç»„ä»¶
        user_input = gr.Textbox(
            placeholder="è¯·è¾“å…¥é—®é¢˜...",
            scale=7,
            container=False,
            label="é—®é¢˜è¾“å…¥"
        )

        # æ“ä½œæŒ‰é’®
        with gr.Column(scale=1):
            submit_btn = gr.Button("å‘é€", variant="primary")
            clear_btn = gr.Button("æ¸…ç©ºæ‰€æœ‰")
    # äº‹ä»¶ç»‘å®š
    # è§†é¢‘ä¸Šä¼ äº‹ä»¶
    video_input.change(
        fn=update_video,
        inputs=[video_input],
        outputs=[video_status]
    )

    # åˆ é™¤è§†é¢‘æŒ‰é’®äº‹ä»¶
    clear_video_btn.click(
        fn=lambda: (None, "è§†é¢‘å·²æ¸…é™¤ï¼Œè¯·ä¸Šä¼ æ–°è§†é¢‘ã€‚"),  # ä½¿ç”¨lambdaç›´æ¥è¿”å›æ­£ç¡®ç±»å‹
        inputs=None,
        outputs=[video_input, video_status]
    )

    # å‘é€æŒ‰é’®äº‹ä»¶
    submit_btn.click(
        fn=chat_fn,
        inputs=[user_input, chatbot, video_input],
        outputs=[user_input, chatbot]
    )

    # è¾“å…¥æ¡†å›è½¦äº‹ä»¶ - ä½¿ç”¨ä¸éœ€è¦è§†é¢‘å‚æ•°çš„å‡½æ•°
    user_input.submit(
        fn=chat_without_video_update,
        inputs=[user_input, chatbot],
        outputs=[user_input, chatbot]
    )
    
    # æ¸…ç©ºæŒ‰é’®äº‹ä»¶
    clear_btn.click(
        fn=lambda: ([], "", "å›¾ç‰‡å’Œå¯¹è¯å·²æ¸…ç©ºï¼Œè¯·é‡æ–°ä¸Šä¼ å›¾ç‰‡ã€‚", None),  # ä¿®å¤è¿”å›å€¼
        inputs=None,
        outputs=[chatbot, user_input, video_status, video_input],
        queue=False
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(server_name="127.0.0.1", server_port=7860)