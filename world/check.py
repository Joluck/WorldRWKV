from datasets import load_from_disk, concatenate_datasets, load_dataset
import os
from .utils import pipeline, check_vision_token, process_tokens, bytes_to_audio, process_vision_token, read_and_merge_json, load_jsonl_files, load_vision_text
from tqdm import tqdm


data_file = "/DATA/disk1/step3/xhs8"
subdirs = [os.path.join(data_file, d) for d in os.listdir(data_file) 
        if os.path.isdir(os.path.join(data_file, d))]

# è®°å½•æ•°æ®é›†æ¥æºä¿¡æ¯
dataset_source_map = {}  # idx -> dataset_name
current_idx = 0

if subdirs:
    # åŠ è½½æ¯ä¸ªå­ç›®å½•çš„æ•°æ®é›†
    datasets = []
    for subdir in subdirs:
        dataset = load_from_disk(subdir)
        dataset_name = os.path.basename(subdir)
        
        # è®°å½•è¿™ä¸ªæ•°æ®é›†ä¸­æ¯ä¸ªæ ·æœ¬çš„æ¥æº
        for i in range(len(dataset)):
            dataset_source_map[current_idx + i] = dataset_name
        
        datasets.append(dataset)
        current_idx += len(dataset)
        print(f"åŠ è½½æ•°æ®é›† {dataset_name}: {len(dataset)} æ¡")
    
    # è¿æ¥æ‰€æœ‰æ•°æ®é›†
    data = concatenate_datasets(datasets)
    print(f"å·²è¿æ¥{len(datasets)}ä¸ªå­ç›®å½•çš„æ•°æ®é›†ï¼Œæ€»å¤§å°: {len(data)}")
else:
    # å¦‚æœæ²¡æœ‰å­ç›®å½•ï¼Œç›´æ¥åŠ è½½ä¸»ç›®å½•
    data = load_from_disk(data_file)
    dataset_name = os.path.basename(data_file)
    for i in range(len(data)):
        dataset_source_map[i] = dataset_name
    print(f"ä»å•ä¸€ç›®å½•åŠ è½½æ•°æ®é›† {dataset_name}ï¼Œå¤§å°: {len(data)}")

for idx in tqdm(range(0, len(data), 1000), desc="Processing samples (every 1000)"):
    try:
        sample = data[idx]
        conversation_text = sample['conversations']
        text_tokens, text_labels = check_vision_token(conversation_text)
        print(f"Successfully processed sample {idx}")
    except Exception as e:
        # è·å–æ•°æ®é›†æ¥æº
        source_dataset = dataset_source_map.get(idx, "Unknown")
        
        print(f"\n{'='*60}")
        print(f"âŒ Error processing sample {idx}")
        print(f"ğŸ“ Source dataset: {source_dataset}")
        print(f"ğŸ› Error: {e}")
        print(f"ğŸ“„ Sample data:")
        try:
            # å®‰å…¨åœ°æ‰“å°æ ·æœ¬æ•°æ®ï¼Œé¿å…è¿‡é•¿çš„è¾“å‡º
            sample_str = str(sample)
            if len(sample_str) > 1000:
                sample_str = sample_str[:1000] + "...(truncated)"
            print(sample_str)
        except:
            print("æ— æ³•æ‰“å°æ ·æœ¬æ•°æ®")
        print(f"{'='*60}\n")
        continue

